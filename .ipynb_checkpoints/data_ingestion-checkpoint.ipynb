{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a73c421b",
   "metadata": {},
   "source": [
    "### Name: Manoj Kumar Thangaraj\n",
    "### Course: LISUM01\n",
    "\n",
    "### Week 6 Task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65292e9",
   "metadata": {},
   "source": [
    "## Task:\n",
    "\n",
    "* Take any csv/text file of 2+ GB of your choice. --- (You can do this assignment on Google colab)\n",
    "\n",
    "* Read the file ( Present approach of reading the file )\n",
    "\n",
    "* Try different methods of file reading eg: Dask, Modin, Ray, pandas and present your findings in term of computational     efficiency\n",
    "\n",
    "* Perform basic validation on data columns : eg: remove special character , white spaces from the col name\n",
    "\n",
    "* As you already know the schema hence create a YAML file and write the column name in YAML file. --define separator of   \n",
    "  read and write file, column name in YAML\n",
    "\n",
    "* Validate number of columns and column name of ingested file with YAML.\n",
    "\n",
    "* Write the file in pipe separated text file (|) in gz format.\n",
    "\n",
    "* Create a summary of the file:\n",
    "\n",
    "    Total number of rows,\n",
    "\n",
    "    total number of columns\n",
    "\n",
    "    file size\n",
    "    \n",
    "# Data Ingestion sample code walkthrough\n",
    "\n",
    "## \n",
    "  > Create a utility file\n",
    "  \n",
    "  > Config file creation\n",
    "  \n",
    "  > Data ingestion pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3978be3e",
   "metadata": {},
   "source": [
    "**Let's write an utility file and import the required libraries**\n",
    "\n",
    "Define a function for reading and writing the file in **YAML** format and column validation.\n",
    "\n",
    "    i) read_config for file reading in YAML,\n",
    "    ii) replacer for removing uncessary charcters,\n",
    "    iii) col_header_val for column validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ba37c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting testutility.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile testutility.py\n",
    "\n",
    "#Import the required libraries\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import gc\n",
    "import re\n",
    "\n",
    "def read_config_file(filepath):\n",
    "    '''Takes in the filepath and read the file\n",
    "    Args: Filepath\n",
    "    return: Yaml config'''\n",
    "    with open(filepath, 'r') as stream:   #open the file as read only\n",
    "        try:\n",
    "            return yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:     #output an error if file not found\n",
    "            logging.error(exc)\n",
    "\n",
    "\n",
    "def replacer(string, char):\n",
    "    '''Takes in the string and the character and return after removing unnecessary characters\n",
    "    Args: string, char\n",
    "    return: string'''\n",
    "    pattern = char + '{2,}'\n",
    "    string = re.sub(pattern, char, string)   #using regex remove unnecessary charcters\n",
    "    return string\n",
    "\n",
    "def col_header_val(df,table_config):\n",
    "    '''\n",
    "    replace whitespaces in the column\n",
    "    and standardized column names\n",
    "    Args: dataframe, table_config from YAML\n",
    "    returns: validated columns after preprocessing\n",
    "    '''\n",
    "    df.columns = df.columns.str.lower()       #lower case\n",
    "    df.columns = df.columns.str.replace('[^\\w]','_',regex=True) #remove tags and replace them with underscore\n",
    "    df.columns = list(map(lambda x: x.strip('_'), list(df.columns))) #strip out underscore\n",
    "    df.columns = list(map(lambda x: replacer(x,'_'), list(df.columns)))\n",
    "    expected_col = list(map(lambda x: x.lower(),  table_config['columns']))\n",
    "    expected_col.sort()\n",
    "    df.columns =list(map(lambda x: x.lower(), list(df.columns)))\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    if len(df.columns) == len(expected_col) and list(expected_col)  == list(df.columns):\n",
    "        print(\"column name and column length validation passed\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"column name and column length validation failed\")\n",
    "        mismatched_columns_file = list(set(df.columns).difference(expected_col))\n",
    "        print(\"Following File columns are not in the YAML file\",mismatched_columns_file)\n",
    "        missing_YAML_file = list(set(expected_col).difference(df.columns))\n",
    "        print(\"Following YAML columns are not in the file uploaded\",missing_YAML_file)\n",
    "        logging.info(f'df columns: {df.columns}')\n",
    "        logging.info(f'expected columns: {expected_col}')\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b59c1af",
   "metadata": {},
   "source": [
    "### Write YAML File\n",
    "\n",
    "The file taken from Kaggle website on the following link https://www.kaggle.com/mkechinov/ecommerce-behavior-data-from-multi-category-store?select=2019-Oct.csv where we can two datasets present and 0ct-2019.csv is the downloaded dataset.\n",
    "\n",
    " source of Link: link to this page and link to REES46 Marketing Platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26850774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting file.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile file.yaml\n",
    "file_type: csv\n",
    "dataset_name: Oct\n",
    "file_name: Oct\n",
    "table_name: Events\n",
    "inbound_delimiter: \",\"\n",
    "outbound_delimiter: \"|\"\n",
    "skip_leading_rows: 1\n",
    "total_rows: 42448764\n",
    "columns: \n",
    "    - event_time\n",
    "    - event_type\n",
    "    - product_id\n",
    "    - category_id\n",
    "    - category_code\n",
    "    - brand\n",
    "    - price\n",
    "    - user_id\n",
    "    - user_session\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "066f0202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read config file\n",
    "import testutility as util\n",
    "config_data = util.read_config_file(\"file.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60088d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_type': 'csv',\n",
       " 'dataset_name': 'Oct',\n",
       " 'file_name': 'Oct',\n",
       " 'table_name': 'Events',\n",
       " 'inbound_delimiter': ',',\n",
       " 'outbound_delimiter': '|',\n",
       " 'skip_leading_rows': 1,\n",
       " 'total_rows': 42448764,\n",
       " 'columns': ['event_time',\n",
       "  'event_type',\n",
       "  'product_id',\n",
       "  'category_id',\n",
       "  'category_code',\n",
       "  'brand',\n",
       "  'price',\n",
       "  'user_id',\n",
       "  'user_session']}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspecting data of config file\n",
    "config_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e3be1f",
   "metadata": {},
   "source": [
    "The config data files are read in the dictionary format and we can see we have **keys and values**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41839170",
   "metadata": {},
   "source": [
    "### File is read through pandas, yaml config and dask library and their computational efficiency is compared at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc0d871e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The processing time through pandas library is 508.51016330718994 seconds\n"
     ]
    }
   ],
   "source": [
    "# Normal reading process of the file through pandas\n",
    "import pandas as pd\n",
    "import time\n",
    "start_time = time.time()\n",
    "df_sample = pd.read_csv(\"Oct.csv\",delimiter=',')\n",
    "end_time = time.time()\n",
    "df_sample.head()\n",
    "Total_time = end_time - start_time\n",
    "print(\"The processing time through pandas library is\",Total_time,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26ba7051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_code</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-01 00:00:00 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>44600062</td>\n",
       "      <td>2103807459595387724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shiseido</td>\n",
       "      <td>35.79</td>\n",
       "      <td>541312140</td>\n",
       "      <td>72d76fde-8bb3-4e00-8c23-a032dfed738c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-10-01 00:00:00 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>3900821</td>\n",
       "      <td>2053013552326770905</td>\n",
       "      <td>appliances.environment.water_heater</td>\n",
       "      <td>aqua</td>\n",
       "      <td>33.20</td>\n",
       "      <td>554748717</td>\n",
       "      <td>9333dfbd-b87a-4708-9857-6336556b0fcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-10-01 00:00:01 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>17200506</td>\n",
       "      <td>2053013559792632471</td>\n",
       "      <td>furniture.living_room.sofa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>543.10</td>\n",
       "      <td>519107250</td>\n",
       "      <td>566511c2-e2e3-422b-b695-cf8e6e792ca8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-10-01 00:00:01 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>1307067</td>\n",
       "      <td>2053013558920217191</td>\n",
       "      <td>computers.notebook</td>\n",
       "      <td>lenovo</td>\n",
       "      <td>251.74</td>\n",
       "      <td>550050854</td>\n",
       "      <td>7c90fc70-0e80-4590-96f3-13c02c18c713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-10-01 00:00:04 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>1004237</td>\n",
       "      <td>2053013555631882655</td>\n",
       "      <td>electronics.smartphone</td>\n",
       "      <td>apple</td>\n",
       "      <td>1081.98</td>\n",
       "      <td>535871217</td>\n",
       "      <td>c6bd7419-2748-4c56-95b4-8cec9ff8b80d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                event_time event_type  product_id          category_id  \\\n",
       "0  2019-10-01 00:00:00 UTC       view    44600062  2103807459595387724   \n",
       "1  2019-10-01 00:00:00 UTC       view     3900821  2053013552326770905   \n",
       "2  2019-10-01 00:00:01 UTC       view    17200506  2053013559792632471   \n",
       "3  2019-10-01 00:00:01 UTC       view     1307067  2053013558920217191   \n",
       "4  2019-10-01 00:00:04 UTC       view     1004237  2053013555631882655   \n",
       "\n",
       "                         category_code     brand    price    user_id  \\\n",
       "0                                  NaN  shiseido    35.79  541312140   \n",
       "1  appliances.environment.water_heater      aqua    33.20  554748717   \n",
       "2           furniture.living_room.sofa       NaN   543.10  519107250   \n",
       "3                   computers.notebook    lenovo   251.74  550050854   \n",
       "4               electronics.smartphone     apple  1081.98  535871217   \n",
       "\n",
       "                           user_session  \n",
       "0  72d76fde-8bb3-4e00-8c23-a032dfed738c  \n",
       "1  9333dfbd-b87a-4708-9857-6336556b0fcc  \n",
       "2  566511c2-e2e3-422b-b695-cf8e6e792ca8  \n",
       "3  7c90fc70-0e80-4590-96f3-13c02c18c713  \n",
       "4  c6bd7419-2748-4c56-95b4-8cec9ff8b80d  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check the dataframe\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9073a928",
   "metadata": {},
   "source": [
    "Now we will check for the number of rows in total for this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "700a5382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of rows in this file is 42448764\n"
     ]
    }
   ],
   "source": [
    "no_of_rows = len(df_sample)\n",
    "\n",
    "print(\"The total number of rows in this file is\",no_of_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fddf42c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The processing time through YAML library is 1076.5904235839844 seconds\n"
     ]
    }
   ],
   "source": [
    "# read the file using config file\n",
    "file_type = config_data['file_type']\n",
    "source_file = \"./\" + config_data['file_name'] + f'.{file_type}'\n",
    "#print(\"\",source_file)\n",
    "start_time = time.time()\n",
    "df = pd.read_csv(source_file,config_data['inbound_delimiter'])\n",
    "end_time = time.time()\n",
    "Total_time = end_time - start_time\n",
    "df.head()\n",
    "print(\"The processing time through YAML library is\",Total_time,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d72e390d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of rows in this file is 42448764\n"
     ]
    }
   ],
   "source": [
    "#checking the number of rows\n",
    "no_of_rows = len(df)\n",
    "\n",
    "#print the result\n",
    "print(\"The total number of rows in this file is\",no_of_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d74f2888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The processing time through pandas library is 0.5963287353515625 seconds\n"
     ]
    }
   ],
   "source": [
    "# read the file using dask file\n",
    "import dask.dataframe as dd\n",
    "start_time = time.time()\n",
    "df_dask = dd.read_csv('Oct.csv')\n",
    "end_time = time.time()\n",
    "Total_time = end_time - start_time\n",
    "print(\"The processing time through pandas library is\",Total_time,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f7e0271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of rows in this file is 42448764\n"
     ]
    }
   ],
   "source": [
    "#checking the number of rows\n",
    "no_of_rows = len(df_dask)\n",
    "\n",
    "#print the result\n",
    "print(\"The total number of rows in this file is\",no_of_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8171dabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_code</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-01 00:00:00 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>44600062</td>\n",
       "      <td>2103807459595387724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shiseido</td>\n",
       "      <td>35.79</td>\n",
       "      <td>541312140</td>\n",
       "      <td>72d76fde-8bb3-4e00-8c23-a032dfed738c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-10-01 00:00:00 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>3900821</td>\n",
       "      <td>2053013552326770905</td>\n",
       "      <td>appliances.environment.water_heater</td>\n",
       "      <td>aqua</td>\n",
       "      <td>33.20</td>\n",
       "      <td>554748717</td>\n",
       "      <td>9333dfbd-b87a-4708-9857-6336556b0fcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-10-01 00:00:01 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>17200506</td>\n",
       "      <td>2053013559792632471</td>\n",
       "      <td>furniture.living_room.sofa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>543.10</td>\n",
       "      <td>519107250</td>\n",
       "      <td>566511c2-e2e3-422b-b695-cf8e6e792ca8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-10-01 00:00:01 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>1307067</td>\n",
       "      <td>2053013558920217191</td>\n",
       "      <td>computers.notebook</td>\n",
       "      <td>lenovo</td>\n",
       "      <td>251.74</td>\n",
       "      <td>550050854</td>\n",
       "      <td>7c90fc70-0e80-4590-96f3-13c02c18c713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-10-01 00:00:04 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>1004237</td>\n",
       "      <td>2053013555631882655</td>\n",
       "      <td>electronics.smartphone</td>\n",
       "      <td>apple</td>\n",
       "      <td>1081.98</td>\n",
       "      <td>535871217</td>\n",
       "      <td>c6bd7419-2748-4c56-95b4-8cec9ff8b80d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                event_time event_type  product_id          category_id  \\\n",
       "0  2019-10-01 00:00:00 UTC       view    44600062  2103807459595387724   \n",
       "1  2019-10-01 00:00:00 UTC       view     3900821  2053013552326770905   \n",
       "2  2019-10-01 00:00:01 UTC       view    17200506  2053013559792632471   \n",
       "3  2019-10-01 00:00:01 UTC       view     1307067  2053013558920217191   \n",
       "4  2019-10-01 00:00:04 UTC       view     1004237  2053013555631882655   \n",
       "\n",
       "                         category_code     brand    price    user_id  \\\n",
       "0                                  NaN  shiseido    35.79  541312140   \n",
       "1  appliances.environment.water_heater      aqua    33.20  554748717   \n",
       "2           furniture.living_room.sofa       NaN   543.10  519107250   \n",
       "3                   computers.notebook    lenovo   251.74  550050854   \n",
       "4               electronics.smartphone     apple  1081.98  535871217   \n",
       "\n",
       "                           user_session  \n",
       "0  72d76fde-8bb3-4e00-8c23-a032dfed738c  \n",
       "1  9333dfbd-b87a-4708-9857-6336556b0fcc  \n",
       "2  566511c2-e2e3-422b-b695-cf8e6e792ca8  \n",
       "3  7c90fc70-0e80-4590-96f3-13c02c18c713  \n",
       "4  c6bd7419-2748-4c56-95b4-8cec9ff8b80d  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the dataframe\n",
    "df_dask.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c507eaa6",
   "metadata": {},
   "source": [
    "### Now we will validate the dataframe read through libraries with YAML config file, the modules can be imported through testutilities.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6aba1890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column name and column length validation passed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validate the header of the file\n",
    "util.col_header_val(df_sample,config_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af835e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns of files are: Index(['event_time', 'event_type', 'product_id', 'category_id',\n",
      "       'category_code', 'brand', 'price', 'user_id', 'user_session'],\n",
      "      dtype='object')\n",
      "columns of YAML are: ['event_time', 'event_type', 'product_id', 'category_id', 'category_code', 'brand', 'price', 'user_id', 'user_session']\n"
     ]
    }
   ],
   "source": [
    "#print the number of columns on both config and pandas file\n",
    "print(\"columns of files are:\" ,df_sample.columns)\n",
    "print(\"columns of YAML are:\" ,config_data['columns'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b26187",
   "metadata": {},
   "source": [
    "### As per the pipeline, if our file is accepted or rejected based on the validation, further actions are taken, which is commented out on the below code as they are out of scope for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "497e7b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column name and column length validation passed\n",
      "column validation passed\n"
     ]
    }
   ],
   "source": [
    "if util.col_header_val(df_sample,config_data)==0:\n",
    "    print(\"validation failed\")\n",
    "    # write code to reject the file\n",
    "else:\n",
    "    print(\"column validation passed\")\n",
    "    # write the code to perform further action\n",
    "    # in the pipleine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b3f33a",
   "metadata": {},
   "source": [
    "### Once the files are validated and passed, we can write the file in the compressed 'gz' format for further use. The code can be found below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0b64a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a pandas dataframe to gzipped CSV file\n",
    "df.to_csv(\"compressed.csv.gz\", \n",
    "           index=False, \n",
    "           compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa07708",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "- The total number of rows in the file are 42448764.\n",
    "- The total number of the columns in the file are 8.\n",
    "- The total size of the compressed file is 1.57GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1508c171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
